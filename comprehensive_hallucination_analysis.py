"""
Comprehensive Hallucination Analysis Report Generator
Analyzes patterns in hallucination-prone questions and provides recommendations
"""

import pandas as pd
import json
import re
from collections import Counter, defaultdict
from pathlib import Path
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import os

class HallucinationPatternAnalyzer:
    """Analyze patterns in questions that lead to hallucinations"""
    
    def __init__(self):
        self.hallucination_patterns = defaultdict(list)
        self.question_types = defaultdict(list)
        self.keywords_analysis = defaultdict(list)
        
    def analyze_question_type(self, question: str) -> str:
        """Categorize question type based on content"""
        q_lower = question.lower()
        
        # Question word patterns
        if any(word in q_lower for word in ["ai l√†", "who is", "who was"]):
            return "Nh√¢n v·∫≠t/T√™n ri√™ng"
        elif any(word in q_lower for word in ["nƒÉm n√†o", "when", "khi n√†o"]):
            return "Th·ªùi gian"
        elif any(word in q_lower for word in ["·ªü ƒë√¢u", "where", "t·∫°i ƒë√¢u"]):
            return "ƒê·ªãa ƒëi·ªÉm"
        elif any(word in q_lower for word in ["bao nhi√™u", "how much", "how many", "s·ªë l∆∞·ª£ng"]):
            return "S·ªë li·ªáu"
        elif any(word in q_lower for word in ["c√¥ng th·ª©c", "formula", "ph∆∞∆°ng tr√¨nh"]):
            return "C√¥ng th·ª©c khoa h·ªçc"
        elif any(word in q_lower for word in ["nguy√™n t·ªë", "element", "h√≥a h·ªçc"]):
            return "H√≥a h·ªçc"
        elif any(word in q_lower for word in ["protein", "enzyme", "gen", "dna", "rna"]):
            return "Sinh h·ªçc"
        elif any(word in q_lower for word in ["h√†nh tinh", "planet", "sao", "thi√™n vƒÉn"]):
            return "Thi√™n vƒÉn"
        elif any(word in q_lower for word in ["t·ªëc ƒë·ªô", "speed", "v·∫≠n t·ªëc", "gia t·ªëc"]):
            return "V·∫≠t l√Ω"
        elif any(word in q_lower for word in ["g√¨ l√†", "what is", "ƒë·ªãnh nghƒ©a"]):
            return "ƒê·ªãnh nghƒ©a"
        else:
            return "T·ªïng qu√°t"
    
    def extract_keywords(self, question: str) -> list:
        """Extract key terms from question"""
        # Remove common Vietnamese question words
        stop_words = ["l√†", "g√¨", "ai", "·ªü", "ƒë√¢u", "bao", "nhi√™u", "nƒÉm", "n√†o", "c√≥", "c·ªßa", "trong", "ƒë∆∞·ª£c", "v√†", "v·ªõi"]
        
        # Clean and tokenize
        words = re.findall(r'\b\w+\b', question.lower())
        keywords = [word for word in words if len(word) > 2 and word not in stop_words]
        
        return keywords
    
    def analyze_all_results(self, results_data: dict):
        """Analyze hallucination patterns across all APIs"""
        all_hallucinations = []
        
        for (api, dataset), result in results_data.items():
            if "graded_data" in result:
                df = result["graded_data"]
                
                # Find hallucination cases
                direct_hallu = df[df['direct_hallucination'] == True]
                selfcrit_hallu = df[df['selfcrit_hallucination'] == True]
                
                for _, row in direct_hallu.iterrows():
                    all_hallucinations.append({
                        "api": api,
                        "dataset": dataset,
                        "question": row['question'],
                        "correct_answer": row['gold_answer'],
                        "llm_answer": row['direct_answer'],
                        "prompt_type": "direct"
                    })
                
                for _, row in selfcrit_hallu.iterrows():
                    all_hallucinations.append({
                        "api": api,
                        "dataset": dataset,
                        "question": row['question'],
                        "correct_answer": row['gold_answer'],
                        "llm_answer": row.get('selfcrit_final_span', row['selfcrit_answer']),
                        "prompt_type": "selfcrit"
                    })
        
        # Analyze patterns
        for case in all_hallucinations:
            question = case['question']
            question_type = self.analyze_question_type(question)
            keywords = self.extract_keywords(question)
            
            self.hallucination_patterns[question_type].append(case)
            self.question_types[question_type].append(question)
            self.keywords_analysis[question_type].extend(keywords)
    
    def get_pattern_statistics(self):
        """Get statistics about hallucination patterns"""
        stats = {}
        
        for q_type, cases in self.hallucination_patterns.items():
            api_counts = Counter([case['api'] for case in cases])
            prompt_counts = Counter([case['prompt_type'] for case in cases])
            
            # Most common keywords for this question type
            keyword_counts = Counter(self.keywords_analysis[q_type])
            common_keywords = keyword_counts.most_common(5)
            
            stats[q_type] = {
                "total_hallucinations": len(cases),
                "api_distribution": dict(api_counts),
                "prompt_distribution": dict(prompt_counts),
                "common_keywords": [word for word, count in common_keywords],
                "sample_questions": [case['question'] for case in cases[:3]]
            }
        
        return stats
    
    def generate_recommendations(self, stats: dict) -> dict:
        """Generate specific recommendations for each question type"""
        recommendations = {}
        
        for q_type, data in stats.items():
            total = data['total_hallucinations']
            recommendations[q_type] = {
                "risk_level": "Cao" if total > 5 else "Trung b√¨nh" if total > 2 else "Th·∫•p",
                "total_cases": total,
                "recommendations": []
            }
            
            # Specific recommendations based on question type
            if q_type == "Nh√¢n v·∫≠t/T√™n ri√™ng":
                recommendations[q_type]["recommendations"] = [
                    "Th√™m c·∫£nh b√°o: 'N·∫øu kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ t√™n ng∆∞·ªùi, h√£y n√≥i r√µ l√† kh√¥ng bi·∫øt'",
                    "S·ª≠ d·ª•ng prompt: 'Ch·ªâ tr·∫£ l·ªùi n·∫øu b·∫°n ho√†n to√†n ch·∫Øc ch·∫Øn v·ªÅ t√™n ng∆∞·ªùi'",
                    "Th√™m context: 'Ki·ªÉm tra k·ªπ t√™n ri√™ng tr∆∞·ªõc khi tr·∫£ l·ªùi'"
                ]
            elif q_type == "Th·ªùi gian":
                recommendations[q_type]["recommendations"] = [
                    "Th√™m prompt: 'N·∫øu kh√¥ng ch·∫Øc v·ªÅ nƒÉm/th·ªùi gian ch√≠nh x√°c, h√£y n√≥i kho·∫£ng th·ªùi gian'",
                    "C·∫£nh b√°o: 'C√°c th√¥ng tin th·ªùi gian c·∫ßn ƒë∆∞·ª£c ki·ªÉm ch·ª©ng c·∫©n th·∫≠n'",
                    "S·ª≠ d·ª•ng: 'Tr·∫£ l·ªùi d·∫°ng kho·∫£ng th·ªùi gian thay v√¨ nƒÉm c·ª• th·ªÉ n·∫øu kh√¥ng ch·∫Øc'"
                ]
            elif q_type == "S·ªë li·ªáu":
                recommendations[q_type]["recommendations"] = [
                    "Th√™m prompt: 'Ch·ªâ ƒë∆∞a ra con s·ªë n·∫øu ho√†n to√†n ch·∫Øc ch·∫Øn'",
                    "S·ª≠ d·ª•ng: 'ƒê∆∞a ra kho·∫£ng s·ªë thay v√¨ con s·ªë ch√≠nh x√°c n·∫øu kh√¥ng ch·∫Øc'",
                    "C·∫£nh b√°o: 'C√°c con s·ªë c·∫ßn ƒë∆∞·ª£c x√°c minh t·ª´ ngu·ªìn ƒë√°ng tin c·∫≠y'"
                ]
            elif q_type == "C√¥ng th·ª©c khoa h·ªçc":
                recommendations[q_type]["recommendations"] = [
                    "Th√™m: 'Ki·ªÉm tra l·∫°i c√¥ng th·ª©c tr∆∞·ªõc khi ƒë∆∞a ra'",
                    "S·ª≠ d·ª•ng: 'N·∫øu kh√¥ng ch·∫Øc v·ªÅ c√¥ng th·ª©c ch√≠nh x√°c, h√£y m√¥ t·∫£ nguy√™n l√Ω thay th·∫ø'",
                    "C·∫£nh b√°o: 'C√¥ng th·ª©c khoa h·ªçc c·∫ßn ƒë·ªô ch√≠nh x√°c cao'"
                ]
            else:
                recommendations[q_type]["recommendations"] = [
                    "S·ª≠ d·ª•ng prompt t·ªïng qu√°t: 'N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y th·ªÉ hi·ªán s·ª± kh√¥ng ch·∫Øc ch·∫Øn'",
                    "Th√™m: 'Ki·ªÉm tra l·∫°i th√¥ng tin tr∆∞·ªõc khi tr·∫£ l·ªùi'",
                    "Khuy·∫øn kh√≠ch: 'S·ª≠ d·ª•ng ng√¥n ng·ªØ th·∫≠n tr·ªçng khi kh√¥ng ch·∫Øc ch·∫Øn'"
                ]
        
        return recommendations

def generate_comprehensive_hallucination_report(output_path: str = "comprehensive_hallucination_analysis.docx"):
    """Generate comprehensive hallucination analysis report"""
    
    # Load all results
    from ui.components.enhanced_analytics import load_all_existing_results
    
    results_data = load_all_existing_results()
    
    if not results_data:
        print("‚ùå No results found to analyze")
        return None
    
    print("üîç Analyzing hallucination patterns...")
    
    # Initialize analyzer
    analyzer = HallucinationPatternAnalyzer()
    analyzer.analyze_all_results(results_data)
    
    # Get statistics and recommendations
    stats = analyzer.get_pattern_statistics()
    recommendations = analyzer.generate_recommendations(stats)
    
    # Create Word document
    doc = Document()
    
    # Title
    title = doc.add_heading("B√ÅO C√ÅO PH√ÇN T√çCH HALLUCINATION T·ªîNG H·ª¢P", 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # Subtitle
    subtitle = doc.add_paragraph(f"Ph√¢n t√≠ch m·∫´u h√¨nh hallucination v√† ƒë·ªÅ xu·∫•t c·∫£i thi·ªán prompt")
    subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"Ng√†y t·∫°o: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}")
    
    # Executive Summary
    doc.add_heading("1. T√ìM T·∫ÆT ƒêI·ªÄU H√ÄNH", level=1)
    
    total_apis = len(set([api for api, dataset in results_data.keys()]))
    total_datasets = len(set([dataset for api, dataset in results_data.keys()]))
    total_hallucinations = sum([data['total_hallucinations'] for data in stats.values()])
    
    summary_items = [
        f"S·ªë API ƒë∆∞·ª£c ph√¢n t√≠ch: {total_apis} (OpenAI, DeepSeek, Gemini, Ollama)",
        f"S·ªë dataset ƒë∆∞·ª£c ki·ªÉm tra: {total_datasets}",
        f"T·ªïng s·ªë tr∆∞·ªùng h·ª£p hallucination: {total_hallucinations}",
        f"S·ªë lo·∫°i c√¢u h·ªèi ƒë∆∞·ª£c ph√¢n lo·∫°i: {len(stats)}",
        f"Lo·∫°i c√¢u h·ªèi c√≥ nguy c∆° cao nh·∫•t: {max(stats.keys(), key=lambda x: stats[x]['total_hallucinations']) if stats else 'Kh√¥ng c√≥'}"
    ]
    
    for item in summary_items:
        p = doc.add_paragraph()
        p.add_run(f"‚Ä¢ {item}").bold = True
    
    # Detailed Analysis by Question Type
    doc.add_heading("2. PH√ÇN T√çCH CHI TI·∫æT THEO LO·∫†I C√ÇU H·ªéI", level=1)
    
    # Sort by hallucination count
    sorted_types = sorted(stats.items(), key=lambda x: x[1]['total_hallucinations'], reverse=True)
    
    for i, (q_type, data) in enumerate(sorted_types, 1):
        doc.add_heading(f"2.{i} {q_type}", level=2)
        
        # Statistics
        p = doc.add_paragraph()
        p.add_run("Th·ªëng k√™:").bold = True
        
        stats_items = [
            f"S·ªë tr∆∞·ªùng h·ª£p hallucination: {data['total_hallucinations']}",
            f"Ph√¢n b·ªë theo API: {', '.join([f'{api}: {count}' for api, count in data['api_distribution'].items()])}",
            f"Ph√¢n b·ªë theo prompt: {', '.join([f'{prompt}: {count}' for prompt, count in data['prompt_distribution'].items()])}",
            f"T·ª´ kh√≥a ph·ªï bi·∫øn: {', '.join(data['common_keywords'])}"
        ]
        
        for stat in stats_items:
            doc.add_paragraph(f"  ‚Ä¢ {stat}")
        
        # Sample questions
        p = doc.add_paragraph()
        p.add_run("V√≠ d·ª• c√¢u h·ªèi d·ªÖ g√¢y hallucination:").bold = True
        
        for j, question in enumerate(data['sample_questions'], 1):
            doc.add_paragraph(f"  {j}. {question}")
        
        # Recommendations
        rec_data = recommendations[q_type]
        p = doc.add_paragraph()
        p.add_run(f"M·ª©c ƒë·ªô r·ªßi ro: {rec_data['risk_level']}").bold = True
        
        p = doc.add_paragraph()
        p.add_run("Khuy·∫øn ngh·ªã c·∫£i thi·ªán prompt:").bold = True
        
        for rec in rec_data['recommendations']:
            doc.add_paragraph(f"  ‚úì {rec}")
        
        doc.add_paragraph()  # Empty line
    
    # Comprehensive Recommendations
    doc.add_heading("3. KHUY·∫æN NGH·ªä T·ªîNG QU√ÅT", level=1)
    
    general_recommendations = [
        "**Prompt Strategy c∆° b·∫£n:**",
        "‚Ä¢ Lu√¥n y√™u c·∫ßu LLM th·ªÉ hi·ªán s·ª± kh√¥ng ch·∫Øc ch·∫Øn khi kh√¥ng bi·∫øt",
        "‚Ä¢ S·ª≠ d·ª•ng c·ª•m t·ª´ 'N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y n√≥i kh√¥ng bi·∫øt'",
        "‚Ä¢ Th√™m self-critique cho c√°c c√¢u h·ªèi c√≥ nguy c∆° cao",
        "",
        "**Theo t·ª´ng lo·∫°i c√¢u h·ªèi:**",
        "‚Ä¢ C√¢u h·ªèi v·ªÅ t√™n ri√™ng: Y√™u c·∫ßu x√°c minh ngu·ªìn",
        "‚Ä¢ C√¢u h·ªèi v·ªÅ s·ªë li·ªáu: Ch·∫•p nh·∫≠n kho·∫£ng thay v√¨ con s·ªë ch√≠nh x√°c",
        "‚Ä¢ C√¢u h·ªèi v·ªÅ th·ªùi gian: S·ª≠ d·ª•ng kho·∫£ng th·ªùi gian thay v√¨ nƒÉm c·ª• th·ªÉ",
        "‚Ä¢ C√¢u h·ªèi v·ªÅ c√¥ng th·ª©c: Y√™u c·∫ßu ki·ªÉm tra l·∫°i c√¥ng th·ª©c",
        "",
        "**Monitoring v√† ƒë√°nh gi√°:**",
        "‚Ä¢ Theo d√µi t·ª∑ l·ªá hallucination theo t·ª´ng lo·∫°i c√¢u h·ªèi",
        "‚Ä¢ Th∆∞·ªùng xuy√™n c·∫≠p nh·∫≠t prompt d·ª±a tr√™n k·∫øt qu·∫£ m·ªõi",
        "‚Ä¢ S·ª≠ d·ª•ng self-critique prompting cho c√°c ch·ªß ƒë·ªÅ c√≥ nguy c∆° cao"
    ]
    
    for rec in general_recommendations:
        if rec.startswith("**"):
            p = doc.add_paragraph()
            p.add_run(rec.replace("**", "")).bold = True
        else:
            doc.add_paragraph(rec)
    
    # API Specific Analysis
    doc.add_heading("4. PH√ÇN T√çCH THEO API", level=1)
    
    api_analysis = defaultdict(lambda: defaultdict(int))
    for q_type, data in stats.items():
        for api, count in data['api_distribution'].items():
            api_analysis[api][q_type] = count
    
    for api, type_counts in api_analysis.items():
        doc.add_heading(f"4.{list(api_analysis.keys()).index(api)+1} {api.upper()}", level=2)
        
        total_api_hallu = sum(type_counts.values())
        most_problematic = max(type_counts.items(), key=lambda x: x[1]) if type_counts else ("Kh√¥ng c√≥", 0)
        
        doc.add_paragraph(f"T·ªïng hallucination: {total_api_hallu}")
        doc.add_paragraph(f"Lo·∫°i c√¢u h·ªèi problematic nh·∫•t: {most_problematic[0]} ({most_problematic[1]} cases)")
        
        # API specific recommendations
        if api.lower() == "gemini":
            doc.add_paragraph("Khuy·∫øn ngh·ªã: Gemini c·∫ßn prompt conservative h∆°n cho c√¢u h·ªèi factual")
        elif api.lower() == "openai":
            doc.add_paragraph("Khuy·∫øn ngh·ªã: OpenAI c√≥ th·ªÉ s·ª≠ d·ª•ng self-critique hi·ªáu qu·∫£")
        elif api.lower() == "deepseek":
            doc.add_paragraph("Khuy·∫øn ngh·ªã: DeepSeek cho k·∫øt qu·∫£ t·ªët v·ªõi self-critique prompting")
        elif api.lower() == "ollama":
            doc.add_paragraph("Khuy·∫øn ngh·ªã: Ollama c·∫ßn prompt ƒë∆°n gi·∫£n v√† r√µ r√†ng")
    
    # Improved Prompt Templates
    doc.add_heading("5. M·∫™U PROMPT ƒê∆Ø·ª¢C C·∫¢I THI·ªÜN", level=1)
    
    prompt_templates = {
        "Conservative Direct Prompt": """
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI ch√≠nh x√°c v√† th·∫≠n tr·ªçng. 
QUAN TR·ªåNG: N·∫øu b·∫°n kh√¥ng ho√†n to√†n ch·∫Øc ch·∫Øn v·ªÅ c√¢u tr·∫£ l·ªùi, h√£y n√≥i "T√¥i kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ th√¥ng tin n√†y."
Ch·ªâ tr·∫£ l·ªùi khi b·∫°n c√≥ ƒë·ªô tin c·∫≠y cao.

C√¢u h·ªèi: {question}
""",
        "Enhanced Self-Critique Prompt": """
Nhi·ªám v·ª•: Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† t·ª± ki·ªÉm tra.

B∆∞·ªõc 1 - Tr·∫£ l·ªùi nh√°p: ƒê∆∞a ra c√¢u tr·∫£ l·ªùi ban ƒë·∫ßu
B∆∞·ªõc 2 - T·ª± ki·ªÉm tra: 
- T√¥i c√≥ ch·∫Øc ch·∫Øn 100% v·ªÅ th√¥ng tin n√†y kh√¥ng?
- C√≥ kh·∫£ nƒÉng t√¥i nh·∫ßm l·∫´n ho·∫∑c b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng?
- T√¥i c√≥ c·∫ßn th√™m c·∫£nh b√°o v·ªÅ ƒë·ªô tin c·∫≠y kh√¥ng?
B∆∞·ªõc 3 - Tr·∫£ l·ªùi cu·ªëi c√πng: ƒê∆∞a ra c√¢u tr·∫£ l·ªùi sau khi ƒë√£ ki·ªÉm tra

C√¢u h·ªèi: {question}
""",
        "Domain-Specific Prompt (Science)": """
B·∫°n l√† chuy√™n gia khoa h·ªçc. Khi tr·∫£ l·ªùi:
- Ch·ªâ ƒë∆∞a ra th√¥ng tin khoa h·ªçc ƒë√£ ƒë∆∞·ª£c x√°c minh
- N·∫øu kh√¥ng ch·∫Øc v·ªÅ con s·ªë ch√≠nh x√°c, ƒë∆∞a ra kho·∫£ng ∆∞·ªõc t√≠nh
- N·∫øu kh√¥ng ch·∫Øc v·ªÅ c√¥ng th·ª©c, m√¥ t·∫£ nguy√™n l√Ω thay th·∫ø
- Lu√¥n th√™m "c·∫ßn ki·ªÉm ch·ª©ng th√™m" n·∫øu kh√¥ng ho√†n to√†n ch·∫Øc ch·∫Øn

C√¢u h·ªèi: {question}
"""
    }
    
    for template_name, template_content in prompt_templates.items():
        doc.add_heading(template_name, level=2)
        p = doc.add_paragraph(template_content)
        p.style = 'Intense Quote'
    
    # Save document
    doc.save(output_path)
    print(f"‚úÖ Comprehensive report generated: {output_path}")
    
    return output_path, stats, recommendations

if __name__ == "__main__":
    generate_comprehensive_hallucination_report()