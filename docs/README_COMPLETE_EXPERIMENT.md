# NghiÃªn cá»©u Hallucination Detection vá»›i Enhanced Multi-LLM Framework

## ğŸ¯ Má»¥c tiÃªu nÃ¢ng cao

NghiÃªn cá»©u comprehensive so sÃ¡nh **direct prompting** vs **self-critique prompting** Ä‘á»ƒ giáº£m hallucination trong Q&A tiáº¿ng Viá»‡t vá»›i enhanced visualization vÃ  analysis trÃªn 4 LLM APIs: **OpenAI GPT-4**, **DeepSeek**, **Google Gemini Pro**, vÃ  **Ollama**.

### ÄÃ³ng gÃ³p má»›i:
- ğŸ¯ **Enhanced UI Dashboard**: Step-by-step self-critique visualization
- ğŸ“Š **Advanced Analytics**: 716+ hallucination cases analysis
- ğŸ† **Model Ranking System**: Comprehensive performance comparison
- ğŸ” **Prompt Transparency**: Exact prompt inspection capabilities

## ğŸ—ï¸ Kiáº¿n trÃºc dá»± Ã¡n nÃ¢ng cao

### Enhanced Workflow:
1. **Data Preparation**: Datasets trong `data/` vá»›i 4 domains khÃ¡c nhau
2. **Multi-API Inference**: Unified `src/api_runner.py` vá»›i prompt saving
3. **Advanced Evaluation**: `src/evaluator.py` vá»›i enhanced grading logic
4. **Interactive Analysis**: `ui/app.py` vá»›i real-time dashboard
5. **Comprehensive Comparison**: `analyze_models.py` vá»›i composite scoring
6. **Documentation**: Updated docs vá»›i detailed guides

### Enhanced Project Structure:
```
ğŸ“¦ halu2/
â”œâ”€â”€ ğŸ“‚ src/                          # Core enhanced logic
â”‚   â”œâ”€â”€ api_runner.py                # Unified API interface (4 providers)
â”‚   â””â”€â”€ evaluator.py                 # Advanced evaluation vá»›i prompt tracking
â”œâ”€â”€ ğŸ“‚ ui/                           # Enhanced Streamlit dashboard
â”‚   â”œâ”€â”€ app.py                       # Main UI vá»›i hallucination analysis
â”‚   â”œâ”€â”€ experiment_runner.py         # Backend experiment management
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ analytics.py             # Basic analytics
â”‚       â””â”€â”€ enhanced_analytics.py    # Advanced hallucination visualization
â”œâ”€â”€ ğŸ“‚ data/                         # Curated datasets
â”‚   â”œâ”€â”€ astronomy_hard.csv           # 50 astronomy questions
â”‚   â”œâ”€â”€ mathematics_hard.csv         # 50 math problems
â”‚   â”œâ”€â”€ questions_50_hard.csv        # 50 general knowledge
â”‚   â”œâ”€â”€ scientific_facts_basic.csv   # 100 scientific facts
â”‚   â””â”€â”€ results/                     # Organized by API
â”‚       â”œâ”€â”€ openai/                  # GPT-4 results vá»›i prompts
â”‚       â”œâ”€â”€ deepseek/                # DeepSeek results vá»›i prompts
â”‚       â”œâ”€â”€ gemini/                  # Gemini Pro results vá»›i prompts
â”‚       â””â”€â”€ ollama/                  # Ollama results vá»›i prompts
â”œâ”€â”€ ğŸ“‚ configs/                      # API configuration management
â”œâ”€â”€ ğŸ“‚ scripts/                      # Analysis utilities
â”œâ”€â”€ ğŸ“‚ docs/                         # Updated documentation
â”œâ”€â”€ analyze_models.py                # Comprehensive model comparison
â”œâ”€â”€ run_comprehensive_experiments.py # Full pipeline automation
â””â”€â”€ requirements.txt                 # Updated dependencies
```

## âš¡ Enhanced Quick Start

### 1. Complete Installation
```bash
# Clone repository
git clone <repository-url>
cd halu2

# Install all dependencies
pip install -r requirements.txt
```

### 2. Enhanced API Configuration
```bash
# Create config file tá»« template
copy configs\config.example.json configs\config.json

# Edit configs\config.json vá»›i API keys:
{
  "openai": {"api_key": "sk-your-openai-key"},
  "deepseek": {"api_key": "sk-your-deepseek-key", "base_url": "https://api.deepseek.com"},
  "gemini": {"api_key": "your-google-gemini-key"},
  "ollama": {"base_url": "http://localhost:11434"}
}
```

### 3. Launch Enhanced Dashboard
```bash
# Quick launch (recommended)
launch_ui.bat

# Manual launch
streamlit run ui\app.py --server.port 8502
```

### 4. Run Complete Analysis
```bash
# Full experiment pipeline
python run_comprehensive_experiments.py

# Model comparison analysis
python analyze_models.py

# Interactive menu
python main.py
```

## ğŸ“‹ Enhanced Experiment Workflow

### BÆ°á»›c 1: Chuáº©n bá»‹ datasets
```bash
# Táº¡o thÃªm 2 dataset public
python prep_additional_datasets.py

# Káº¿t quáº£: natural_questions_50.csv, fever_claims_50.csv (hoáº·c squad_50.csv)
```

### BÆ°á»›c 2: Cháº¡y inference trÃªn cÃ¡c models

**OpenAI GPT:**
```bash
set INPUT_CSV=questions_50.csv
set OUT_CSV=openai/results_raw.csv
python openai_run.py
```

**DeepSeek:**
```bash
set INPUT_CSV=questions_50.csv  
set OUT_CSV=deepseek/results_raw.csv
set DEEPSEEK_MODEL=deepseek-chat
python deepseek_run.py
```

**Gemini Pro:**
```bash
set INPUT_CSV=questions_50.csv
set OUT_CSV=gemini/results_raw.csv
set GEMINI_MODEL=gemini-1.5-flash
python gemini_run.py
```

**Ollama (Local):**
```bash
# Äáº£m báº£o ollama serve Ä‘ang cháº¡y
ollama run llama3.2

set INPUT_CSV=questions_50.csv
set OUT_CSV=ollama/results_raw.csv
set MODEL_NAME=llama3.2
python run_ollama_eval.py
```

### BÆ°á»›c 3: Cháº¥m Ä‘iá»ƒm káº¿t quáº£
```bash
set INPUT_QA=questions_50.csv
set INPUT_RAW=openai/results_raw.csv
set OUT_GRADED=openai/results_graded.csv
python grade_and_report.py
```

### BÆ°á»›c 4: PhÃ¢n tÃ­ch patterns gÃ¢y hallucination
```bash
python analyze_hallucination_patterns.py
# Táº¡o: pattern_analysis.txt, improved_prompts.py
```

### BÆ°á»›c 5: Test prompt templates cáº£i tiáº¿n
```bash
set API_PROVIDER=openai
set API_KEY=%OPENAI_API_KEY%
set INPUT_CSV=scientific_facts_basic.csv
python test_improved_prompts.py
```

### BÆ°á»›c 6: So sÃ¡nh cross-model
```bash
python cross_model_comparison.py
# Táº¡o: cross_model_comparison_report.txt, model_comparison_summary.csv
```

## ğŸ”¬ PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡

### Äá»‹nh nghÄ©a Hallucination:
- **ÄÃºng**: Ground truth xuáº¥t hiá»‡n trong cÃ¢u tráº£ lá»i (sau normalization)
- **Uncertainty**: CÃ³ tá»« khÃ³a "khÃ´ng cháº¯c", "not sure", "cÃ³ thá»ƒ", etc.
- **Hallucination**: Tráº£ lá»i **SAI** nhÆ°ng **KHÃ”NG** thá»ƒ hiá»‡n uncertainty

### Metrics:
- `accuracy_direct`: Tá»· lá»‡ Ä‘Ãºng vá»›i direct prompting
- `accuracy_selfcrit`: Tá»· lá»‡ Ä‘Ãºng vá»›i self-critique prompting  
- `hallu_rate_direct`: Tá»· lá»‡ hallucination vá»›i direct prompting
- `hallu_rate_selfcrit`: Tá»· lá»‡ hallucination vá»›i self-critique prompting
- `accuracy_gain`: Cáº£i thiá»‡n accuracy tá»« self-critique
- `hallu_reduction`: Giáº£m hallucination tá»« self-critique

## ğŸ¨ Prompt Templates

### Baseline (Direct):
```
Báº¡n lÃ  trá»£ lÃ½ chÃ­nh xÃ¡c vá» sá»± kiá»‡n. Tráº£ lá»i ngáº¯n gá»n má»™t Ä‘oáº¡n. 
Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i 'khÃ´ng cháº¯c'.
CÃ¢u há»i: {q}
```

### Self-Critique:
```
Nhiá»‡m vá»¥: Tráº£ lá»i rá»“i tá»± kiá»ƒm tra tÃ­nh chÃ­nh xÃ¡c vÃ  sá»­a láº¡i náº¿u cáº§n.
BÆ°á»›c 1 â€” NhÃ¡p: tráº£ lá»i ngáº¯n.
BÆ°á»›c 2 â€” Tá»± kiá»ƒm: liá»‡t kÃª Ä‘iá»ƒm cÃ³ thá»ƒ sai hoáº·c thiáº¿u.
BÆ°á»›c 3 â€” Cuá»‘i cÃ¹ng: Ä‘Æ°a Ä‘Ã¡p Ã¡n cuá»‘i cÃ¹ng. Náº¿u khÃ´ng cháº¯c, hÃ£y nÃ³i rÃµ khÃ´ng cháº¯c.
CÃ¢u há»i: {q}
```

### Improved Templates (tá»± Ä‘á»™ng táº¡o):
- **Conservative**: Cáº©n tháº­n hÆ¡n, chá»‰ tráº£ lá»i khi cháº¯c cháº¯n
- **Evidence-based**: YÃªu cáº§u nÃªu má»©c Ä‘á»™ tin cáº­y
- **Calibrated**: Tráº£ lá»i vá»›i xÃ¡c suáº¥t tin cáº­y
- **Meta-cognitive**: Tá»± há»i "tÃ´i cÃ³ thá»±c sá»± biáº¿t khÃ´ng?"

## ğŸ“Š Káº¿t quáº£ máº«u

```
MODEL COMPARISON SUMMARY:
OpenAI GPT-4: 
  - Accuracy (direct): 0.720
  - Hallucination rate: 0.140
  - Self-critique improvement: +0.040

DeepSeek Chat:
  - Accuracy (direct): 0.680  
  - Hallucination rate: 0.180
  - Self-critique improvement: +0.020

Gemini Pro:
  - Accuracy (direct): 0.640
  - Hallucination rate: 0.220
  - Self-critique improvement: -0.010

Ollama Llama3.2:
  - Accuracy (direct): 0.560
  - Hallucination rate: 0.280
  - Self-critique improvement: +0.060
```

## ğŸ”§ Cáº¥u hÃ¬nh nÃ¢ng cao

### Environment Variables:
```bash
# Model selection
OPENAI_MODEL=gpt-4o-mini
DEEPSEEK_MODEL=deepseek-chat  
GEMINI_MODEL=gemini-1.5-flash
MODEL_NAME=llama3.2  # for Ollama

# Dataset selection
INPUT_CSV=scientific_facts_basic.csv
OUT_CSV=results_raw.csv

# API settings
TIMEOUT_S=120
OLLAMA_HOST=http://localhost:11434
```

### Custom Datasets:
Táº¡o CSV vá»›i format:
```csv
question,ground_truth
"Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  gÃ¬?","HÃ  Ná»™i"
"Kim loáº¡i nÃ o cÃ³ kÃ½ hiá»‡u Au?","vÃ ng"
```

## ğŸ“ˆ PhÃ¢n tÃ­ch nÃ¢ng cao

### Pattern Analysis:
Script `analyze_hallucination_patterns.py` tá»± Ä‘á»™ng phÃ¡t hiá»‡n:
- Loáº¡i cÃ¢u há»i nÃ o dá»… gÃ¢y hallucination (wh-questions, superlatives, technical terms)
- Risk factors trong cáº¥u trÃºc cÃ¢u há»i
- Correlation giá»¯a Ä‘á»™ phá»©c táº¡p vÃ  hallucination rate

### Question Difficulty:
TÃ­nh difficulty score dá»±a trÃªn tá»· lá»‡ hallucination trÃªn nhiá»u models:
```
difficulty_score = (direct_hallu + selfcrit_hallu) / (2 * n_models)
```

## ğŸ¯ Sá»­ dá»¥ng káº¿t quáº£ cho paper

### Key Findings Ä‘á»ƒ bÃ¡o cÃ¡o:
1. **Cross-model comparison**: Model nÃ o cÃ³ hallucination rate tháº¥p nháº¥t?
2. **Self-critique effectiveness**: CÃ³ cáº£i thiá»‡n accuracy/giáº£m hallucination?
3. **Question patterns**: Loáº¡i cÃ¢u há»i nÃ o khÃ³ nháº¥t?
4. **Prompt engineering**: Template nÃ o hiá»‡u quáº£ nháº¥t?

### Generated Reports:
- `cross_model_comparison_report.txt`: BÃ¡o cÃ¡o tá»•ng quan
- `model_comparison_summary.csv`: Data cho analysis
- `pattern_analysis.txt`: PhÃ¢n tÃ­ch patterns
- `*.png`: Visualizations

## âš ï¸ Troubleshooting

### API Errors:
- **Rate limiting**: TÄƒng sleep time trong script
- **Timeout**: TÄƒng `TIMEOUT_S`
- **Auth**: Kiá»ƒm tra API keys

### Ollama Issues:
```bash
# Start Ollama
ollama serve

# Pull model
ollama pull llama3.2

# Test connection
curl http://localhost:11434/api/tags
```

### Dependencies:
```bash
# Missing packages
pip install datasets  # for HuggingFace datasets
pip install python-docx  # for Word reports
pip install google-generativeai  # for Gemini
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [TruthfulQA Dataset](https://huggingface.co/datasets/truthful_qa)
- [OpenAI API Docs](https://platform.openai.com/docs)
- [DeepSeek API](https://platform.deepseek.com/api-docs)
- [Google AI API](https://ai.google.dev/docs)
- [Ollama Documentation](https://ollama.ai/docs)

## ğŸ¤ Contribution

Äá»ƒ má»Ÿ rá»™ng nghiÃªn cá»©u:
1. ThÃªm LLM má»›i: Táº¡o `{model}_run.py` theo pattern existing
2. ThÃªm dataset: Update `prep_additional_datasets.py`  
3. ThÃªm prompt template: Update `test_improved_prompts.py`
4. ThÃªm metric: Update `grade_and_report.py`

---

**Happy researching! ğŸš€**