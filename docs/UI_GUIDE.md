# ğŸ§  Enhanced Hallucination Detection Dashboard - UI Guide

## ğŸ¯ Tá»•ng quan giao diá»‡n má»›i

Giao diá»‡n UI nÃ¢ng cao cho phÃ©p báº¡n:
- âœ… **Multi-API Support**: OpenAI, DeepSeek, Gemini, Ollama vá»›i unified interface
- âœ… **Enhanced Analytics**: PhÃ¢n tÃ­ch hallucination cases vá»›i step-by-step reasoning
- âœ… **Visual Indicators**: Badges vÃ  icons phÃ¢n biá»‡t Direct vs Self-Critique
- âœ… **Real-time Dashboard**: Live metrics vÃ  interactive filtering
- âœ… **Model Comparison**: Comprehensive ranking vá»›i composite scoring
- âœ… **Prompt Transparency**: Xem exact prompts Ä‘Æ°á»£c sá»­ dá»¥ng
- âœ… **Export Capabilities**: BÃ¡o cÃ¡o Word, CSV, JSON

## ğŸš€ Khá»Ÿi Ä‘á»™ng nhanh

### BÆ°á»›c 1: Setup mÃ´i trÆ°á»ng nÃ¢ng cao

```bash
# CÃ i Ä‘áº·t dependencies Ä‘Ã£ cáº­p nháº­t
pip install -r requirements.txt

# Khá»Ÿi Ä‘á»™ng vá»›i port má»›i (recommended)
launch_ui.bat           # Tá»± Ä‘á»™ng má»Ÿ http://localhost:8502
```

### BÆ°á»›c 2: Setup API Keys (Cáº­p nháº­t)

Táº¡o file `configs/config.json` tá»« template:
```json
{
  "openai": {
    "api_key": "sk-your-openai-key"
  },
  "deepseek": {
    "api_key": "sk-your-deepseek-key",
    "base_url": "https://api.deepseek.com"
  },
  "gemini": {
    "api_key": "your-google-gemini-key"
  },
  "ollama": {
    "base_url": "http://localhost:11434"
  }
}
```

### BÆ°á»›c 3: Datasets cÃ³ sáºµn

Datasets Ä‘Ã£ Ä‘Æ°á»£c chuáº©n bá»‹ trong `data/`:
- **astronomy_hard.csv** - 50 cÃ¢u há»i thiÃªn vÄƒn khÃ³
- **mathematics_hard.csv** - 50 cÃ¢u há»i toÃ¡n há»c phá»©c táº¡p
- **questions_50_hard.csv** - 50 cÃ¢u há»i tá»•ng há»£p khÃ³
- **scientific_facts_basic.csv** - 100 sá»± kiá»‡n khoa há»c cÆ¡ báº£n
```

### BÆ°á»›c 4: Khá»Ÿi Ä‘á»™ng Enhanced UI

```bash
# Khá»Ÿi Ä‘á»™ng dashboard nÃ¢ng cao
streamlit run ui/app.py --server.port 8502
```

Truy cáº­p: **http://localhost:8502**

## ğŸ“‹ HÆ°á»›ng dáº«n sá»­ dá»¥ng Enhanced Dashboard

### ğŸ¯ Main Navigation Tabs

#### Tab 1: Configuration & Setup
- **API Status Check**: Xem tráº¡ng thÃ¡i káº¿t ná»‘i real-time
- **Model Selection**: Chá»n models cho tá»«ng API
- **Dataset Preview**: Xem trÆ°á»›c ná»™i dung datasets

#### Tab 2: Run Experiments  
- **Multi-API Selection**: Chá»n APIs muá»‘n cháº¡y Ä‘á»“ng thá»i
- **Batch Processing**: Cháº¡y táº¥t cáº£ combinations (API Ã— Dataset)
- **Progress Tracking**: Real-time progress vá»›i detailed status

#### Tab 3: Results & Analytics
- **Overview Metrics**: Tá»•ng quan performance táº¥t cáº£ models
- **Interactive Charts**: Plotly charts vá»›i drill-down capabilities
- **Performance Comparison**: Direct vs Self-Critique analysis

#### â­ Tab 4: Hallucination Cases Analysis (Má»›i!)
- **ğŸ¯ Visual Indicators**: Badges phÃ¢n biá»‡t Direct vs Self-Critique cases
- **ğŸ§  Step-by-Step Display**: Parse vÃ  hiá»ƒn thá»‹ tá»«ng bÆ°á»›c reasoning
- **ğŸ” Interactive Filtering**: Filter theo API, dataset, strategy
- **ğŸ“‹ Prompt Transparency**: Xem exact prompts Ä‘Æ°á»£c sá»­ dá»¥ng
- **ğŸ“Š Case Statistics**: Metrics breakdown per category

#### â­ Tab 5: Model Comparison & Ranking (Má»›i!)
- **ğŸ† Comprehensive Ranking**: Top 4 LLMs vá»›i composite scores
- **ğŸ“ˆ Performance Breakdown**: Chi tiáº¿t metrics tá»«ng model
- **ğŸ“Š Cross-Dataset Analysis**: Consistency across domains
- **ğŸ“‹ Detailed Explanations**: Giáº£i thÃ­ch ranking rationale

### ğŸ” Enhanced Analytics Features

#### ğŸ§  Self-Critique Process Visualization
```
BÆ°á»›c 1: NhÃ¡p          â†’ Draft response
BÆ°á»›c 2: Tá»± kiá»ƒm       â†’ Self-verification  
BÆ°á»›c 3: Cuá»‘i cÃ¹ng     â†’ Final refined answer
```

- **Automatic Step Parsing**: Regex extraction cá»§a Vietnamese step markers
- **Structured Display**: Organized presentation vá»›i markdown formatting
- **Content Analysis**: Show reasoning progression

#### ğŸ¯ Visual Case Indicators
- **ğŸ¯ Direct Badge**: Simple prompting strategy
- **ğŸ§  Self-Critique Badge**: Multi-step reasoning strategy  
- **Color Coding**: Green (correct), Red (hallucination), Yellow (uncertain)
- **Interactive Tooltips**: Hover for additional information

#### ğŸ“Š Advanced Filtering System
- **By API Provider**: OpenAI, DeepSeek, Gemini, Ollama
- **By Dataset**: Filter theo domain-specific datasets
- **By Strategy**: Direct vs Self-Critique
- **By Outcome**: Correct, Hallucination, Uncertain
- **Combined Filters**: Multiple criteria simultaneously

### ğŸ“ Enhanced Project Structure

```
halu2/
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                     # Enhanced main UI vá»›i new features
â”‚   â”œâ”€â”€ experiment_runner.py       # Backend experiment management  
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ analytics.py           # Basic analytics components
â”‚       â””â”€â”€ enhanced_analytics.py  # Advanced hallucination analysis
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ astronomy_hard.csv         # 50 astronomy questions
â”‚   â”œâ”€â”€ mathematics_hard.csv       # 50 math problems
â”‚   â”œâ”€â”€ questions_50_hard.csv      # 50 general knowledge  
â”‚   â”œâ”€â”€ scientific_facts_basic.csv # 100 scientific facts
â”‚   â””â”€â”€ results/                   # Organized by API provider
â”‚       â”œâ”€â”€ openai/               # GPT-4 results with prompts
â”‚       â”œâ”€â”€ deepseek/             # DeepSeek results with prompts
â”‚       â”œâ”€â”€ gemini/               # Gemini Pro results with prompts
â”‚       â””â”€â”€ ollama/               # Local model results with prompts
â”œâ”€â”€ analyze_models.py             # Comprehensive model comparison
â”œâ”€â”€ run_comprehensive_experiments.py # Full pipeline automation
â””â”€â”€ configs/
    â”œâ”€â”€ config.json               # API keys configuration  
    â””â”€â”€ config.example.json       # Configuration template
```

## ğŸ† Model Performance Dashboard

### Current Rankings (Real Data)
1. **ğŸ¥‡ Google Gemini Pro**: 56.2/100
   - Best uncertainty detection
   - Consistent performance across domains
   - Excellent self-critique improvement

2. **ğŸ¥ˆ OpenAI GPT-4**: 49.7/100  
   - Strong baseline performance
   - Good balance across metrics
   - Reliable self-critique reasoning

3. **ğŸ¥‰ DeepSeek**: 49.6/100
   - Cost-effective performance
   - Competitive results
   - Good value proposition

4. **ğŸ Ollama (Local)**: 35.2/100
   - Privacy-focused option
   - No API costs
   - Suitable for sensitive data

### Performance Metrics Explained
- **Composite Score**: Weighted average cá»§a correctness, uncertainty detection, hallucination rate
- **Self-Critique Improvement**: Tá»· lá»‡ cáº£i thiá»‡n khi sá»­ dá»¥ng self-critique vs direct
- **Domain Consistency**: Performance stability across different datasets
- **Error Analysis**: Types of mistakes vÃ  patterns

## âš™ï¸ Advanced Configuration

### API Configuration (configs/config.json)
```json
{
  "openai": {
    "api_key": "sk-your-openai-key",
    "model": "gpt-4",
    "temperature": 0.1
  },
  "deepseek": {
    "api_key": "sk-your-deepseek-key", 
    "base_url": "https://api.deepseek.com",
    "model": "deepseek-chat"
  },
  "gemini": {
    "api_key": "your-google-key",
    "model": "gemini-pro"
  },
  "ollama": {
    "base_url": "http://localhost:11434",
    "model": "llama3.2"
  }
}
```

### Environment Variables
```bash
# API Keys
OPENAI_API_KEY=sk-...
DEEPSEEK_API_KEY=sk-...
GOOGLE_API_KEY=AIza...

# Model Selection (optional, cÃ³ default)
OPENAI_MODEL=gpt-4o-mini
DEEPSEEK_MODEL=deepseek-chat
GEMINI_MODEL=gemini-1.5-flash
MODEL_NAME=llama3.2                # for Ollama

# Paths (optional, cÃ³ default)
DATA_DIR=data
RESULTS_DIR=data/results

# Timeouts
TIMEOUT_S=300                       # Per experiment timeout
```

### Streamlit Configuration
Táº¡o `.streamlit/config.toml`:
```toml
[server]
port = 8501
headless = false

[theme]
primaryColor = "#FF6B6B"
backgroundColor = "#FFFFFF"
secondaryBackgroundColor = "#F0F2F6"
textColor = "#262730"
```

## ğŸ› Troubleshooting

### Common Issues:

1. **"No datasets found"**
   ```bash
   # Cháº¡y Ä‘á»ƒ táº¡o datasets
   python prep_additional_datasets.py
   ```

2. **"API unavailable"**
   ```bash
   # Check environment variables
   echo $OPENAI_API_KEY
   
   # Hoáº·c set trong session
   export OPENAI_API_KEY=your_key
   ```

3. **"Ollama not available"**
   ```bash
   # Start Ollama server
   ollama serve
   
   # Check status
   curl http://localhost:11434/api/tags
   ```

4. **"Streamlit not found"**
   ```bash
   # Install dependencies
   pip install streamlit plotly pandas
   ```

5. **"Experiment timeout"**
   - TÄƒng `TIMEOUT_S` environment variable
   - Check internet connection cho cloud APIs
   - Check Ollama service cho local

### Debug Mode:
```bash
# Run vá»›i verbose logging
streamlit run app.py --logger.level=debug

# Check backend separately
python ui_experiment_runner.py
```

## ğŸ“ˆ Performance Tips

1. **Parallel Processing**: UI cháº¡y experiments tuáº§n tá»± Ä‘á»ƒ trÃ¡nh rate limits
2. **Caching**: Existing results Ä‘Æ°á»£c load tá»± Ä‘á»™ng
3. **Memory Management**: Large datasets Ä‘Æ°á»£c chunk processing
4. **Error Recovery**: Individual experiment failures khÃ´ng stop toÃ n bá»™
5. **Progress Tracking**: Real-time updates khÃ´ng block UI

## ğŸ¨ Customization

### ThÃªm API má»›i:
1. Update `API_CONFIGS` trong `app.py`
2. Táº¡o `{api_name}_run.py` script
3. Update `ui_experiment_runner.py`

### ThÃªm metrics má»›i:
1. Update `grade_and_report.py`
2. Update chart functions trong `components/analytics.py`
3. Update export functions

### Custom themes:
1. Modify `.streamlit/config.toml`
2. Update CSS trong `app.py` vá»›i `st.markdown`

## ğŸ† Best Practices

1. **Start Small**: Test vá»›i 1-2 APIs vÃ  datasets trÆ°á»›c
2. **Monitor Resources**: Check RAM/CPU usage vá»›i large experiments  
3. **Save Frequently**: UI tá»± Ä‘á»™ng save, nhÆ°ng export quan trá»ng data
4. **Version Control**: Git track experiment configs vÃ  results
5. **Documentation**: Note experimental settings trong exported reports

---

**Happy Experimenting! ğŸš€**

Giao diá»‡n nÃ y giÃºp báº¡n dá»… dÃ ng so sÃ¡nh hallucination detection across multiple LLMs vÃ  datasets, táº¡o ra insights valuable cho research paper cá»§a báº¡n!